import pandas as pd
from urllib.request import urlopen
import html
from bs4 import BeautifulSoup
import csv

link_SP = urlopen("http://www.fenabrave.org.br/pdf/informativo/automatico/dadosregionais_novo.asp?id=Sao%20Paulo&cap=")
link_SC = urlopen("http://www.fenabrave.org.br/pdf/informativo/automatico/dadosregionais_novo.asp?id=Santa%20Catarina&cap=")
link_MS = urlopen("http://www.fenabrave.org.br/pdf/informativo/automatico/dadosregionais_novo.asp?id=Mato%20Grosso%20do%20Sul&cap=")
link_PR = urlopen("http://www.fenabrave.org.br/pdf/informativo/automatico/dadosregionais_novo.asp?id=Parana&cap=")
link_RJ = urlopen("http://www.fenabrave.org.br/pdf/informativo/automatico/dadosregionais_novo.asp?id=Rio%20de%20Janeiro&cap=")
link_ES = urlopen("http://www.fenabrave.org.br/pdf/informativo/automatico/dadosregionais_novo.asp?id=Esp%EDrito%20Santo&cap=")
link_MG = urlopen("http://www.fenabrave.org.br/pdf/informativo/automatico/dadosregionais_novo.asp?id=Minas%20Gerais&cap=")
link_DF = urlopen("http://www.fenabrave.org.br/pdf/informativo/automatico/dadosregionais_novo.asp?id=Distrito%20Federal&cap=")
link_GO = urlopen("http://www.fenabrave.org.br/pdf/informativo/automatico/dadosregionais_novo.asp?id=Goias&cap=")
link_TO = urlopen("http://www.fenabrave.org.br/pdf/informativo/automatico/dadosregionais_novo.asp?id=Tocantins&cap=")
link_AP = urlopen("http://www.fenabrave.org.br/pdf/informativo/automatico/dadosregionais_novo.asp?id=Amap%E1&cap=")
link_SE = urlopen("http://www.fenabrave.org.br/pdf/informativo/automatico/dadosregionais_novo.asp?id=Sergipe&cap=")
link_AL = urlopen("http://www.fenabrave.org.br/pdf/informativo/automatico/dadosregionais_novo.asp?id=Alagoas&cap=")
link_PE = urlopen("http://www.fenabrave.org.br/pdf/informativo/automatico/dadosregionais_novo.asp?id=Pernambuco&cap=")
link_PB = urlopen("http://www.fenabrave.org.br/pdf/informativo/automatico/dadosregionais_novo.asp?id=Paraiba&cap=")
link_RN = urlopen("http://www.fenabrave.org.br/pdf/informativo/automatico/dadosregionais_novo.asp?id=Rio%20Grande%20do%20Norte&cap=")
link_CE = urlopen("http://www.fenabrave.org.br/pdf/informativo/automatico/dadosregionais_novo.asp?id=Ceara&cap=")
link_PI = urlopen("http://www.fenabrave.org.br/pdf/informativo/automatico/dadosregionais_novo.asp?id=Piaui&cap=")
link_MA = urlopen("http://www.fenabrave.org.br/pdf/informativo/automatico/dadosregionais_novo.asp?id=Maranhao&cap=")
link_RR = urlopen("http://www.fenabrave.org.br/pdf/informativo/automatico/dadosregionais_novo.asp?id=Roraima&cap=")
link_PA = urlopen("http://www.fenabrave.org.br/pdf/informativo/automatico/dadosregionais_novo.asp?id=Para&cap=")
link_RO = urlopen("http://www.fenabrave.org.br/pdf/informativo/automatico/dadosregionais_novo.asp?id=Rond%F4nia&cap=")
link_AC = urlopen("http://www.fenabrave.org.br/pdf/informativo/automatico/dadosregionais_novo.asp?id=Acre&cap=")
link_RS = urlopen("http://www.fenabrave.org.br/pdf/informativo/automatico/dadosregionais_novo.asp?id=Rio%20Grande%20do%20Sul&cap=")
link_AM = urlopen("http://www.fenabrave.org.br/pdf/informativo/automatico/dadosregionais_novo.asp?id=Amazonas&cap=")
link_MT = urlopen("http://www.fenabrave.org.br/pdf/informativo/automatico/dadosregionais_novo.asp?id=Mato%20Grosso&cap=")
link_BA = urlopen("http://www.fenabrave.org.br/pdf/informativo/automatico/dadosregionais_novo.asp?id=Bahia&cap=")

soup_SP = BeautifulSoup(link_SP.read(), "html5lib")
soup_SC = BeautifulSoup(link_SC.read(), "html5lib")
soup_MS = BeautifulSoup(link_MS.read(), "html5lib")
soup_PR = BeautifulSoup(link_PR.read(), "html5lib")
soup_RJ = BeautifulSoup(link_RJ.read(), "html5lib")
soup_ES = BeautifulSoup(link_ES.read(), "html5lib")
soup_MG = BeautifulSoup(link_MG.read(), "html5lib")
soup_DF = BeautifulSoup(link_DF.read(), "html5lib")
soup_GO = BeautifulSoup(link_GO.read(), "html5lib")
soup_TO = BeautifulSoup(link_TO.read(), "html5lib")
soup_AP = BeautifulSoup(link_AP.read(), "html5lib")
soup_SE = BeautifulSoup(link_SE.read(), "html5lib")
soup_AL = BeautifulSoup(link_AL.read(), "html5lib")
soup_PE = BeautifulSoup(link_PE.read(), "html5lib")
soup_PB = BeautifulSoup(link_PB.read(), "html5lib")
soup_RN = BeautifulSoup(link_RN.read(), "html5lib")
soup_CE = BeautifulSoup(link_CE.read(), "html5lib")
soup_PI = BeautifulSoup(link_PI.read(), "html5lib")
soup_MA = BeautifulSoup(link_MA.read(), "html5lib")
soup_RR = BeautifulSoup(link_RR.read(), "html5lib")
soup_PA = BeautifulSoup(link_PA.read(), "html5lib")
soup_RO = BeautifulSoup(link_RO.read(), "html5lib")
soup_AC = BeautifulSoup(link_AC.read(), "html5lib")
soup_RS = BeautifulSoup(link_RS.read(), "html5lib")
soup_AM = BeautifulSoup(link_AM.read(), "html5lib")
soup_MT = BeautifulSoup(link_MT.read(), "html5lib")
soup_BA = BeautifulSoup(link_BA.read(), "html5lib")

extrai_tabela = soup_SP.findAll("table", {"class": "TABELA"})
for tag in extrai_tabela:
        table_str = str(extrai_tabela)
        tabela_pronta = pd.read_html(table_str)[0]
        print(tabela_pronta)